{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Architecture:        x86_64\r\n",
      "CPU op-mode(s):      32-bit, 64-bit\r\n",
      "Byte Order:          Little Endian\r\n",
      "CPU(s):              16\r\n",
      "On-line CPU(s) list: 0-15\r\n",
      "Thread(s) per core:  1\r\n",
      "Core(s) per socket:  1\r\n",
      "Socket(s):           16\r\n",
      "NUMA node(s):        1\r\n",
      "Vendor ID:           GenuineIntel\r\n",
      "CPU family:          6\r\n",
      "Model:               44\r\n",
      "Model name:          Westmere E56xx/L56xx/X56xx (Nehalem-C)\r\n",
      "Stepping:            1\r\n",
      "CPU MHz:             2127.966\r\n",
      "BogoMIPS:            4255.93\r\n",
      "Hypervisor vendor:   KVM\r\n",
      "Virtualization type: full\r\n",
      "L1d cache:           32K\r\n",
      "L1i cache:           32K\r\n",
      "L2 cache:            4096K\r\n",
      "NUMA node0 CPU(s):   0-15\r\n",
      "Flags:               fpu de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 syscall nx lm constant_tsc rep_good nopl pni pclmulqdq ssse3 cx16 sse4_1 sse4_2 x2apic popcnt aes hypervisor lahf_lm\r\n"
     ]
    }
   ],
   "source": [
    "!lscpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "import colorama\n",
    "from colorama import Fore\n",
    "from itertools import chain\n",
    "import matplotlib.pyplot as plt\n",
    "from giverny.isotropic_cube import *\n",
    "from giverny.turbulence_toolkit import *\n",
    "from giverny.turbulence_gizmos.basic_gizmos import *\n",
    "\n",
    "# user-defined parameters for instantiating the isotropic cube.\n",
    "# -----\n",
    "# turbulence dataset name, e.g. \"isotropic8192\" or \"isotropic1024fine\".\n",
    "cube_title = 'isotropic8192'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numba import jit, njit, prange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generates the morton cube representing the turbulence dataset.\n",
    "cube = iso_cube(cube_title = cube_title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define functions\n",
    "\n",
    "# build 16*16*16 bucket\n",
    "def formBucket(voxel_point_value, num_values_per_datapoint, Bucket_length = 16, ):\n",
    "    group_voxel = np.zeros((num_values_per_datapoint,Bucket_length,Bucket_length,Bucket_length))\n",
    "    #Change from ZYX to XYZ, using transpose .T\n",
    "    group_voxel[:,0:8,0:8,0:8] = voxel_point_value[0].T\n",
    "    group_voxel[:,8:16,0:8,0:8] = voxel_point_value[1].T\n",
    "    group_voxel[:,0:8,8:16,0:8] = voxel_point_value[2].T\n",
    "    group_voxel[:,8:16,8:16,0:8] = voxel_point_value[3].T\n",
    "    group_voxel[:,0:8,0:8,8:16] = voxel_point_value[4].T\n",
    "    group_voxel[:,8:16,0:8,8:16] = voxel_point_value[5].T\n",
    "    group_voxel[:,0:8,8:16,8:16] = voxel_point_value[6].T\n",
    "    group_voxel[:,8:16,8:16,8:16] = voxel_point_value[7].T\n",
    "    \n",
    "    return group_voxel\n",
    "\n",
    "# find center coordinates of the bucket (e.g, (7.5 7.5 7.5) for the first bucket)\n",
    "def findCenter(points, dx):\n",
    "    center_point = np.array([points[0], points[1], points[2]])/dx%8\n",
    "    for i in range(len(center_point)):\n",
    "        if (center_point[i] < 3.5):\n",
    "            center_point[i]=center_point[i]+8\n",
    "    return center_point\n",
    "\n",
    "def findCenter_gradient(points, dx):\n",
    "    points = np.round(np.around(points/dx, decimals=1))\n",
    "#    print('points',points)\n",
    "    center_point = np.array([points[0], points[1], points[2]])%8\n",
    "#    print('center_point',center_point)\n",
    "    for i in range(len(center_point)):\n",
    "        if (center_point[i] < 3.5):\n",
    "            center_point[i]=center_point[i]+8\n",
    "    return center_point\n",
    "\n",
    "################################################################################\n",
    "# Coefficients for Lagrange interpolation, 4,6,8th-order\n",
    "################################################################################\n",
    "\n",
    "def getLag4C(fr):\n",
    "    #------------------------------------------------------\n",
    "    # get the 1D vectors for the 8 point Lagrange weights\n",
    "    # inline the constants, and write explicit for loop\n",
    "    # for the C compilation\n",
    "    #------------------------------------------------------\n",
    "    #cdef int n\n",
    "    wN = [1.,-3.,3.,-1.]\n",
    "    g  = np.array([0,1.,0,0])\n",
    "    #----------------------------\n",
    "    # calculate weights if fr>0, and insert into gg\n",
    "    #----------------------------\n",
    "    if (fr>0):\n",
    "        s = 0\n",
    "        for n in range(4):\n",
    "            g[n] = wN[n]/(fr-n+1)\n",
    "            s += g[n]\n",
    "        for n in range(4):\n",
    "            g[n] = g[n]/s\n",
    "            \n",
    "    return g\n",
    "\n",
    "################################################################################\n",
    "# Functions for Lagrange interpolation, 4,6,8th-order\n",
    "################################################################################\n",
    "\n",
    "def interpLag4C(p,u):\n",
    "    #--------------------------------------------------------\n",
    "    # p is an np.array(3) containing the three coordinates\n",
    "    #---------------------------------------------------------\n",
    "    # get the coefficients\n",
    "    #----------------------\n",
    "    ix = p.astype('int')\n",
    "    fr = p-ix\n",
    "    gx = getLag4C(fr[0])\n",
    "    gy = getLag4C(fr[1])\n",
    "    gz = getLag4C(fr[2])\n",
    "    #------------------------------------\n",
    "    # create the 3D kernel from the \n",
    "    # outer product of the 1d kernels\n",
    "    #------------------------------------\n",
    "    gk = np.einsum('i,j,k',gx,gy,gz)\n",
    "    #---------------------------------------\n",
    "    # assemble the 4x4x4 cube and convolve\n",
    "    #---------------------------------------\n",
    "    d = u[:,ix[0]-1:ix[0]+3,ix[1]-1:ix[1]+3,ix[2]-1:ix[2]+3]\n",
    "    ui = np.einsum('ijk,lijk->l',gk,d)\n",
    "    \n",
    "    return ui\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "################################################################################\n",
    "# Coefficients for Hessian (central differencing), 4,6,8th-order\n",
    "################################################################################   \n",
    "@jit(nopython=True)\n",
    "def getNone_Fd4_diagonal(dx):\n",
    "    CenteredFiniteDiffCoeff = [( -1.0 / 12.0 / dx / dx, 4.0 / 3.0 / dx / dx, -15.0 / 6.0 / dx / dx,\n",
    "                                4.0 / 3.0 / dx / dx, -1.0 / 12.0 / dx / dx)]\n",
    "    return CenteredFiniteDiffCoeff\n",
    "\n",
    "@jit(nopython=True)\n",
    "def getNone_Fd4_offdiagonal(dx):\n",
    "    CenteredFiniteDiffCoeff = [(-1.0 / 48.0 / dx / dx,1.0 / 48.0 / dx / dx,-1.0 / 48.0 / dx / dx,1.0 / 48.0 / dx / dx,\n",
    "                               1.0 / 3.0 / dx / dx, -1.0 / 3.0 / dx / dx,1.0 / 3.0 / dx / dx, -1.0 / 3.0 / dx / dx)]\n",
    "    return CenteredFiniteDiffCoeff\n",
    "                \n",
    "\n",
    "#######################################\n",
    "# glue adjacent cornercode\n",
    "def ranges(nums):\n",
    "    nums = sorted(set(nums))\n",
    "    gaps = [[s, e] for s, e in zip(nums, nums[1:]) if s + 512 < e]\n",
    "    edges = iter(nums[:1] + sum(gaps, []) + nums[-1:])\n",
    "    return list(zip(edges, edges))\n",
    "\n",
    "# same as def get_file_for_point\n",
    "def findPath(cube, cornercode):\n",
    "    t = cube.cache[(cube.cache['minLim'] <= cornercode) & (cube.cache['maxLim'] >= cornercode)]\n",
    "    t = t.iloc[0]\n",
    "    db_minLim = t.minLim \n",
    "    db_maxLim = t.maxLim\n",
    "    path = cube.filepaths[f'{t.ProductionDatabaseName}_{var}_{timepoint}']\n",
    "    \n",
    "    return db_minLim, db_maxLim, path\n",
    "\n",
    "def Lag_looKuptable_4(NB):\n",
    "    frac = np.linspace(0,1-1/NB,NB)\n",
    "    LW = []\n",
    "    for fp in frac:\n",
    "        LW.append(getLag4C(fp))\n",
    "        \n",
    "    return LW\n",
    "\n",
    "\n",
    "# https://numba.discourse.group/t/passing-a-list-of-numpy-arrays-into-np-array-with-numba/278\n",
    "@njit(parallel=True)\n",
    "def make_2d(arraylist):\n",
    "    n = len(arraylist)\n",
    "    k = arraylist[0].shape[0]\n",
    "    a2d = np.zeros((n, k))\n",
    "    for i in prange(n):\n",
    "        a2d[i] = arraylist[i]\n",
    "    return(a2d)\n",
    "\n",
    "\n",
    "@jit(nopython=True)#, parallel=True)\n",
    "def HessianNone_Fd4(p,u,dx):\n",
    "    #--------------------------------------------------------\n",
    "    # p is an np.array(3) containing the three coordinates\n",
    "    #---------------------------------------------------------\n",
    "    # get the coefficients\n",
    "    #----------------------\n",
    "    ix = p.astype(np.int64)\n",
    "    CenteredFiniteDiffCoeff_dia = np.array(getNone_Fd4_diagonal(dx))\n",
    "    CenteredFiniteDiffCoeff_offdia = np.array(getNone_Fd4_offdiagonal(dx))\n",
    "    #---------------------------------------\n",
    "    # assemble the 5x5x5 cube and convolve\n",
    "    #---------------------------------------\n",
    "    # diagnoal components\n",
    "    component_x = u[:,ix[0]-2:ix[0]+3,ix[1],ix[2]]\n",
    "    component_y = u[:,ix[0],ix[1]-2:ix[1]+3,ix[2]]\n",
    "    component_z = u[:,ix[0],ix[1],ix[2]-2:ix[2]+3]\n",
    "    \n",
    "#     uii = np.inner(CenteredFiniteDiffCoeff_dia,component_x)\n",
    "    uii = np.dot(CenteredFiniteDiffCoeff_dia,component_x.T)\n",
    "#     print(\"Dot vs. inner: \", np.all(np.dot(CenteredFiniteDiffCoeff_dia,component_x.T) == uii))\n",
    "#     ujj = np.inner(CenteredFiniteDiffCoeff_dia,component_y)\n",
    "    ujj = np.dot(CenteredFiniteDiffCoeff_dia,component_y.T)\n",
    "#     ukk = np.inner(CenteredFiniteDiffCoeff_dia,component_z)\n",
    "    ukk = np.dot(CenteredFiniteDiffCoeff_dia,component_z.T)\n",
    "    \n",
    "    # off-diagnoal components\n",
    "    component_xy = [u[:,ix[0]+2,ix[1]+2,ix[2]],u[:,ix[0]+2,ix[1]-2,ix[2]],u[:,ix[0]-2,ix[1]-2,ix[2]],u[:,ix[0]-2,ix[1]+2,ix[2]],\n",
    "                    u[:,ix[0]+1,ix[1]+1,ix[2]],u[:,ix[0]+1,ix[1]-1,ix[2]],u[:,ix[0]-1,ix[1]-1,ix[2]],u[:,ix[0]-1,ix[1]+1,ix[2]]]\n",
    "#     print(\"component_xy: \", component_xy)\n",
    "    component_xy = make_2d(component_xy)\n",
    "    component_xz = [u[:,ix[0]+2,ix[1],ix[2]+2],u[:,ix[0]+2,ix[1],ix[2]-2],u[:,ix[0]-2,ix[1],ix[2]-2],u[:,ix[0]-2,ix[1],ix[2]+2],\n",
    "                    u[:,ix[0]+1,ix[1],ix[2]+1],u[:,ix[0]+1,ix[1],ix[2]-1],u[:,ix[0]-1,ix[1],ix[2]-1],u[:,ix[0]-1,ix[1],ix[2]+1]]\n",
    "    component_xz = make_2d(component_xz)\n",
    "    component_yz = [u[:,ix[0],ix[1]+2,ix[2]+2],u[:,ix[0],ix[1]+2,ix[2]-2],u[:,ix[0],ix[1]-2,ix[2]-2],u[:,ix[0],ix[1]-2,ix[2]+2],\n",
    "                    u[:,ix[0],ix[1]+1,ix[2]+1],u[:,ix[0],ix[1]+1,ix[2]-1],u[:,ix[0],ix[1]-1,ix[2]-1],u[:,ix[0],ix[1]-1,ix[2]+1]]\n",
    "    component_yz = make_2d(component_yz)\n",
    "    \n",
    "#     uij = np.inner(CenteredFiniteDiffCoeff_offdia,component_xy.T)\n",
    "    uij = np.dot(CenteredFiniteDiffCoeff_offdia,component_xy)\n",
    "    \n",
    "#     print(\"CenteredFiniteDiffCoeff_offdia.shape: \", CenteredFiniteDiffCoeff_offdia.shape)\n",
    "#     print(\"component_xy.T.shape: \", component_xy.T.shape)\n",
    "#     if CenteredFiniteDiffCoeff_dia.shape[1] != component_xy.shape[0]:\n",
    "#         component_x = component_x.T\n",
    "\n",
    "#     if not (np.all(np.dot(CenteredFiniteDiffCoeff_offdia,component_xy) == uij)):\n",
    "#         print(\"Dot-inner: \", np.dot(CenteredFiniteDiffCoeff_offdia,component_xy), \" --- \", uij)\n",
    "    \n",
    "#     uik = np.inner(CenteredFiniteDiffCoeff_offdia,component_xz.T)\n",
    "    uik = np.dot(CenteredFiniteDiffCoeff_offdia,component_xz)\n",
    "#     ujk = np.inner(CenteredFiniteDiffCoeff_offdia,component_yz.T)\n",
    "    ujk = np.dot(CenteredFiniteDiffCoeff_offdia,component_yz)\n",
    "    return uii,uij,uik,ujj,ujk,ukk\n",
    "\n",
    "\n",
    "@jit(nopython=True)#, parallel=True)\n",
    "def forLaplacian(u, ix):\n",
    "    uii =  np.zeros((u.shape[0],4,4,4))\n",
    "    ujj =  np.zeros((u.shape[0],4,4,4))\n",
    "    ukk =  np.zeros((u.shape[0],4,4,4))\n",
    "    uij =  np.zeros((u.shape[0],4,4,4))\n",
    "    uik =  np.zeros((u.shape[0],4,4,4))\n",
    "    ujk =  np.zeros((u.shape[0],4,4,4))\n",
    "    \n",
    "    for i in range(4):\n",
    "        for j in range(4):\n",
    "            for k in prange(4):\n",
    "                uii[:,i,j,k], uij[:,i,j,k], uik[:,i,j,k], ujj[:,i,j,k], ujk[:,i,j,k], ukk[:,i,j,k] = HessianNone_Fd4(np.array([ix[0]-1+i,ix[1]-1+j,ix[2]-1+k]),u,dx)\n",
    "\n",
    "    return uii, ujj, ukk, uij, uik, ujk\n",
    "\n",
    "# @jit(nopython=True)\n",
    "def HessianFd4Lag4L(p,u,dx,LW,NB):\n",
    "    #--------------------------------------------------------\n",
    "    # p is an np.array(3) containing the three coordinates\n",
    "    #---------------------------------------------------------\n",
    "    # get the coefficients\n",
    "    #----------------------\n",
    "    ix = p.astype(np.int64)\n",
    "    fr = p-ix\n",
    "    gx = LW[int(NB*fr[0])]\n",
    "    gy = LW[int(NB*fr[1])]\n",
    "    gz = LW[int(NB*fr[2])]\n",
    "    #------------------------------------\n",
    "    # create the 3D kernel from the \n",
    "    # outer product of the 1d kernels\n",
    "    #------------------------------------\n",
    "    gk = np.einsum('i,j,k',gx,gy,gz)\n",
    "    #---------------------------------------\n",
    "    # assemble the 4x4x4 cube and convolve\n",
    "    #---------------------------------------\n",
    "#     uii =  np.zeros((u.shape[0],4,4,4))\n",
    "#     ujj =  np.zeros((u.shape[0],4,4,4))\n",
    "#     ukk =  np.zeros((u.shape[0],4,4,4))\n",
    "#     uij =  np.zeros((u.shape[0],4,4,4))\n",
    "#     uik =  np.zeros((u.shape[0],4,4,4))\n",
    "#     ujk =  np.zeros((u.shape[0],4,4,4))\n",
    "    \n",
    "#     for i in range(4):\n",
    "#         for j in range(4):\n",
    "#             for k in range(4):\n",
    "#                 uii[:,i,j,k], uij[:,i,j,k], uik[:,i,j,k], ujj[:,i,j,k], ujk[:,i,j,k], ukk[:,i,j,k] = HessianNone_Fd4(np.array([ix[0]-1+i,ix[1]-1+j,ix[2]-1+k]),u,dx)\n",
    "       \n",
    "    uii,uij,uik,ujj,ujk,ukk = forLaplacian(u, ix)\n",
    "    \n",
    "    uii = np.einsum('ijk,lijk->l',gk,uii) #dudxx, dvdxx, dwdxx\n",
    "    ujj = np.einsum('ijk,lijk->l',gk,ujj) #dudyy, dvdyy, dwdyy\n",
    "    ukk = np.einsum('ijk,lijk->l',gk,ukk) #dudzz, dvdzz, dwdzz\n",
    "    \n",
    "    uij = np.einsum('ijk,lijk->l',gk,uij) #dudxy, dvdxy, dwdxy \n",
    "    uik = np.einsum('ijk,lijk->l',gk,uik) #dudxz, dvdxz, dwdxz \n",
    "    ujk = np.einsum('ijk,lijk->l',gk,ujk) #dudyz, dvdyz, dwdyz\n",
    "    \n",
    "    return uii,uij,uik,ujj,ujk,ukk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "dx=2*math.pi/8192\n",
    "#variable = 'pressure'\n",
    "variable = 'velocity'\n",
    "var = get_variable_identifier(variable)\n",
    "# num_values_per_datapoint = 1 for pressure, 3 for velocity\n",
    "num_values_per_datapoint = 3\n",
    "bytes_per_datapoint = 4\n",
    "timepoint = 0\n",
    "\n",
    "# line test:\n",
    "npoints=100\n",
    "B = np.random.uniform(low=0., high=8192., size=(npoints,3))*dx\n",
    "\n",
    "# B is the set of array\n",
    "points = np.floor(B/dx)\n",
    "points = points.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-174-c4ea80cab667>:215: NumbaPerformanceWarning: \u001b[1m\u001b[1m\n",
      "The keyword argument 'parallel=True' was specified but no transformation for parallel execution was possible.\n",
      "\n",
      "To find out why, try turning on parallel diagnostics, see https://numba.pydata.org/numba-doc/latest/user/parallel.html#diagnostics for help.\n",
      "\u001b[1m\n",
      "File \"<ipython-input-174-c4ea80cab667>\", line 148:\u001b[0m\n",
      "\u001b[1m@jit(nopython=True, parallel=True)\n",
      "\u001b[1mdef HessianNone_Fd4(p,u,dx):\n",
      "\u001b[0m\u001b[1m^\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0m\n",
      "  uii[:,i,j,k], uij[:,i,j,k], uik[:,i,j,k], ujj[:,i,j,k], ujk[:,i,j,k], ukk[:,i,j,k] = HessianNone_Fd4(np.array([ix[0]-1+i,ix[1]-1+j,ix[2]-1+k]),u,dx)\n",
      "<ipython-input-174-c4ea80cab667>:215: NumbaPerformanceWarning: \u001b[1m\u001b[1m\u001b[1mnp.dot() is faster on contiguous arrays, called on (array(float64, 2d, C), array(float64, 2d, A))\u001b[0m\u001b[0m\u001b[0m\n",
      "  uii[:,i,j,k], uij[:,i,j,k], uik[:,i,j,k], ujj[:,i,j,k], ujk[:,i,j,k], ukk[:,i,j,k] = HessianNone_Fd4(np.array([ix[0]-1+i,ix[1]-1+j,ix[2]-1+k]),u,dx)\n"
     ]
    },
    {
     "ename": "TypingError",
     "evalue": "Failed in nopython mode pipeline (step: nopython mode backend)\n\u001b[1mFailed in nopython mode pipeline (step: nopython frontend)\n\u001b[1m\u001b[1mNo implementation of function Function(<built-in function setitem>) found for signature:\n \n >>> setitem(array(float64, 1d, A), UniTuple(int64 x 2), float64)\n \nThere are 16 candidate implementations:\n\u001b[1m      - Of which 14 did not match due to:\n      Overload of function 'setitem': File: <numerous>: Line N/A.\n        With argument(s): '(array(float64, 1d, A), UniTuple(int64 x 2), float64)':\u001b[0m\n\u001b[1m       No match.\u001b[0m\n\u001b[1m      - Of which 2 did not match due to:\n      Overload in function 'SetItemBuffer.generic': File: numba/core/typing/arraydecl.py: Line 171.\n        With argument(s): '(array(float64, 1d, A), UniTuple(int64 x 2), float64)':\u001b[0m\n\u001b[1m       Rejected as the implementation raised a specific error:\n         TypeError: cannot index array(float64, 1d, A) with 2 indices: UniTuple(int64 x 2)\u001b[0m\n  raised from /home/idies/miniconda3/envs/py38/lib/python3.8/site-packages/numba/core/typing/arraydecl.py:84\n\u001b[0m\n\u001b[0m\u001b[1mDuring: typing of setitem at <ipython-input-174-c4ea80cab667> (215)\u001b[0m\n\u001b[1m\nFile \"<ipython-input-174-c4ea80cab667>\", line 215:\u001b[0m\n\u001b[1mdef forLaplacian(u, ix):\n    <source elided>\n            for k in prange(4):\n\u001b[1m                uii[:,i,j,k], uij[:,i,j,k], uik[:,i,j,k], ujj[:,i,j,k], ujk[:,i,j,k], ukk[:,i,j,k] = HessianNone_Fd4(np.array([ix[0]-1+i,ix[1]-1+j,ix[2]-1+k]),u,dx)\n\u001b[0m                \u001b[1m^\u001b[0m\u001b[0m\n\n\u001b[0m\u001b[1mDuring: lowering \"id=31[LoopNest(index_variable = parfor_index.1808, range = (0, $const172.4, 1))]{180: <ir.Block at <ipython-input-174-c4ea80cab667> (214)>}Var(parfor_index.1808, <ipython-input-174-c4ea80cab667>:214)\" at <ipython-input-174-c4ea80cab667> (214)\u001b[0m",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mTypingError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-176-e55f0e768b46>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    144\u001b[0m     \u001b[0;31m# need the center coordinate of the bucket (e.g, (7.5, 7.5, 7.5) for the first bucket) to calculate interpolation.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m     \u001b[0mcenter_point\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfindCenter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mB\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 146\u001b[0;31m     \u001b[0mui_Lag\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mHessianFd4Lag4L\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcenter_point\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mBucket\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mLW_Lag\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mNB\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m \u001b[0mt5\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mperf_counter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-174-c4ea80cab667>\u001b[0m in \u001b[0;36mHessianFd4Lag4L\u001b[0;34m(p, u, dx, LW, NB)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[0;31m#                 uii[:,i,j,k], uij[:,i,j,k], uik[:,i,j,k], ujj[:,i,j,k], ujk[:,i,j,k], ukk[:,i,j,k] = HessianNone_Fd4(np.array([ix[0]-1+i,ix[1]-1+j,ix[2]-1+k]),u,dx)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m     \u001b[0muii\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0muij\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0muik\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mujj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mujk\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mukk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mforLaplacian\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    252\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m     \u001b[0muii\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meinsum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ijk,lijk->l'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mgk\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0muii\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#dudxx, dvdxx, dwdxx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/py38/lib/python3.8/site-packages/numba/core/dispatcher.py\u001b[0m in \u001b[0;36m_compile_for_args\u001b[0;34m(self, *args, **kws)\u001b[0m\n\u001b[1;32m    413\u001b[0m                 \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpatch_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    414\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 415\u001b[0;31m             \u001b[0merror_rewrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'typing'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    416\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUnsupportedError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    417\u001b[0m             \u001b[0;31m# Something unsupported is present in the user code, add help info\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/py38/lib/python3.8/site-packages/numba/core/dispatcher.py\u001b[0m in \u001b[0;36merror_rewrite\u001b[0;34m(e, issue_type)\u001b[0m\n\u001b[1;32m    356\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 358\u001b[0;31m                 \u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    360\u001b[0m         \u001b[0margtypes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/py38/lib/python3.8/site-packages/numba/core/utils.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(tp, value, tb)\u001b[0m\n\u001b[1;32m     78\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m     \u001b[0;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypingError\u001b[0m: Failed in nopython mode pipeline (step: nopython mode backend)\n\u001b[1mFailed in nopython mode pipeline (step: nopython frontend)\n\u001b[1m\u001b[1mNo implementation of function Function(<built-in function setitem>) found for signature:\n \n >>> setitem(array(float64, 1d, A), UniTuple(int64 x 2), float64)\n \nThere are 16 candidate implementations:\n\u001b[1m      - Of which 14 did not match due to:\n      Overload of function 'setitem': File: <numerous>: Line N/A.\n        With argument(s): '(array(float64, 1d, A), UniTuple(int64 x 2), float64)':\u001b[0m\n\u001b[1m       No match.\u001b[0m\n\u001b[1m      - Of which 2 did not match due to:\n      Overload in function 'SetItemBuffer.generic': File: numba/core/typing/arraydecl.py: Line 171.\n        With argument(s): '(array(float64, 1d, A), UniTuple(int64 x 2), float64)':\u001b[0m\n\u001b[1m       Rejected as the implementation raised a specific error:\n         TypeError: cannot index array(float64, 1d, A) with 2 indices: UniTuple(int64 x 2)\u001b[0m\n  raised from /home/idies/miniconda3/envs/py38/lib/python3.8/site-packages/numba/core/typing/arraydecl.py:84\n\u001b[0m\n\u001b[0m\u001b[1mDuring: typing of setitem at <ipython-input-174-c4ea80cab667> (215)\u001b[0m\n\u001b[1m\nFile \"<ipython-input-174-c4ea80cab667>\", line 215:\u001b[0m\n\u001b[1mdef forLaplacian(u, ix):\n    <source elided>\n            for k in prange(4):\n\u001b[1m                uii[:,i,j,k], uij[:,i,j,k], uik[:,i,j,k], ujj[:,i,j,k], ujk[:,i,j,k], ukk[:,i,j,k] = HessianNone_Fd4(np.array([ix[0]-1+i,ix[1]-1+j,ix[2]-1+k]),u,dx)\n\u001b[0m                \u001b[1m^\u001b[0m\u001b[0m\n\n\u001b[0m\u001b[1mDuring: lowering \"id=31[LoopNest(index_variable = parfor_index.1808, range = (0, $const172.4, 1))]{180: <ir.Block at <ipython-input-174-c4ea80cab667> (214)>}Var(parfor_index.1808, <ipython-input-174-c4ea80cab667>:214)\" at <ipython-input-174-c4ea80cab667> (214)\u001b[0m"
     ]
    }
   ],
   "source": [
    "# start interpolation\n",
    "t1 = time.perf_counter()\n",
    "NB=100000 # similar with LaginterpLag8C with NB = 1000000\n",
    "LW_Lag = Lag_looKuptable_4(NB)\n",
    "###################################################################################\n",
    "# step one: build unique cornercodes dictionary\n",
    "###################################################################################\n",
    "\n",
    "# print(np.array(LW_Lag))\n",
    "LW_Lag = np.array(LW_Lag) # Ariel added this\n",
    "\n",
    "# find 8 corner points coordinates for each point\n",
    "All_eight_corner_points=[]\n",
    "for point in points:\n",
    "    x_range = [int(point[0]-3), int(point[0]+4)] ##here is changed 9 points are needed for no interpolation\n",
    "    y_range = [int(point[1]-3), int(point[1]+4)]\n",
    "    z_range = [int(point[2]-3), int(point[2]+4)]\n",
    "    axes_ranges = assemble_axis_data([x_range, y_range, z_range])    \n",
    "    box = [list(axis_range) for axis_range in axes_ranges]        \n",
    "\n",
    "    # the order here is how we build bucket later in 'def formbucket'\n",
    "    full_corner_points=((box[0][0],box[1][0],box[2][0]),(box[0][1],box[1][0],box[2][0]),(box[0][0],box[1][1],box[2][0]),\n",
    "                   (box[0][1],box[1][1],box[2][0]),(box[0][0],box[1][0],box[2][1]),(box[0][1],box[1][0],box[2][1]),\n",
    "                   (box[0][0],box[1][1],box[2][1]),(box[0][1],box[1][1],box[2][1]))\n",
    "\n",
    "    All_eight_corner_points.append(full_corner_points)\n",
    "    \n",
    "All_eight_corner_points=tuple(All_eight_corner_points) \n",
    "\n",
    "t2 = time.perf_counter()\n",
    "\n",
    "# find corresponding cornercodes of the 8 corner points for each point\n",
    "points_cornercodes_pool=[]\n",
    "points_cornercodes_temp = []\n",
    "points_cornercodes_all = []\n",
    "\n",
    "num_voxel = []\n",
    "\n",
    "for point in All_eight_corner_points:\n",
    "    points_cornercodes_temp = []\n",
    "    for pp in point:    \n",
    "        datapoint = [p % cube.N for p in pp]\n",
    "        point_cornercode, offset = cube.get_offset(datapoint)\n",
    "        points_cornercodes_temp.append(point_cornercode)\n",
    "    # the number of voxel is always 8 for each queried point so that we can build bucket using 'def formBucket' for any case,\n",
    "    # For point only need one voxel e.g, (3.5,3.5,3.5), points_cornercodes_temp = [0,0,0,0,0,0,0,0], \n",
    "    # For point only need two voxel e.g, (7.5,3.5,3.5), points_cornercodes_temp = [0,512,0,512,0,512,0,512]\n",
    "    # For point only need four voxel e.g, (7.5,7.5,3.5), points_cornercodes_temp = [0,512,1024,1536,0,512,1024,1536]\n",
    "    # ...for the most of cases, it needs 8 voxels\n",
    "    # points_cornercodes_temp store the order that build bucket in 'def formBucket' \n",
    "    num_voxel.append(len(points_cornercodes_temp))\n",
    "    points_cornercodes_all.append(points_cornercodes_temp)\n",
    "\n",
    "# find unique cornercodes for the voxels pool\n",
    "points_cornercodes_pool = np.unique(list(chain.from_iterable(points_cornercodes_all)))\n",
    "\n",
    "t3 = time.perf_counter()\n",
    "\n",
    "# groupe cornercodes in a dictionary: {[path]:[db_minLim]:[cornercodes]}\n",
    "Voxels_in_pool = {}\n",
    "for i in range(len(points_cornercodes_pool)):\n",
    "    cornercode = points_cornercodes_pool[i]\n",
    "    if i==0:\n",
    "        db_minLim, db_maxLim, path = findPath(cube, cornercode)\n",
    "        if path not in Voxels_in_pool:\n",
    "            Voxels_in_pool[path] = {}\n",
    "            if db_minLim not in Voxels_in_pool[path]:\n",
    "                Voxels_in_pool[path][db_minLim] = {}\n",
    "                Voxels_in_pool[path][db_minLim] = ([cornercode])\n",
    "    else:\n",
    "        if cornercode <= db_maxLim:\n",
    "            Voxels_in_pool[path][db_minLim].append(cornercode)\n",
    "        else:\n",
    "            db_minLim, db_maxLim, path = findPath(cube, cornercode)\n",
    "            if path not in Voxels_in_pool:\n",
    "                Voxels_in_pool[path] = {}\n",
    "                if db_minLim not in Voxels_in_pool[path]:\n",
    "                    Voxels_in_pool[path][db_minLim] = {}\n",
    "                    Voxels_in_pool[path][db_minLim] = ([cornercode])\n",
    "                         \n",
    "t3_1 = time.perf_counter()\n",
    "\n",
    "# further groupe adjacent cornercodes in the dictionary: {[path]:[db_minLim]:([cornercodes range], number of voxels)}\n",
    "c = get_constants()\n",
    "for path in Voxels_in_pool:\n",
    "    grouped_voxels_pool = []\n",
    "    for db_minLim in Voxels_in_pool[path]:\n",
    "        Sorted_voxels = np.sort(Voxels_in_pool[path][db_minLim])\n",
    "        #glue cornercodes if they are adjacent\n",
    "        group_voxels = ranges(Sorted_voxels)\n",
    "        for group_voxel in group_voxels:\n",
    "            # the number of glued voxels\n",
    "            number_vox = (group_voxel[1] - group_voxel[0])/512 + 1\n",
    "            grouped_voxels_pool.append([group_voxel, number_vox])\n",
    "        \n",
    "        #update Voxels_in_pool dictionary with glued voxels\n",
    "        Voxels_in_pool[path][db_minLim]=grouped_voxels_pool    \n",
    "        \n",
    "###################################################################################\n",
    "# step two: reading voxel sequentially and build voxels pool\n",
    "###################################################################################\n",
    "\n",
    "t3_2 = time.perf_counter()\n",
    "# Reading data sequentially\n",
    "voxel_value_pool = []\n",
    "for db_file in Voxels_in_pool:\n",
    "    for db_minLim in Voxels_in_pool[db_file]:\n",
    "        morton_voxels_to_read = Voxels_in_pool[db_file][db_minLim]\n",
    "        for morton_data in morton_voxels_to_read:\n",
    "                morton_index_range = morton_data[0]\n",
    "                num_voxels = morton_data[1]\n",
    "\n",
    "                seek_distance = num_values_per_datapoint * bytes_per_datapoint * (morton_index_range[0] - db_minLim)                    \n",
    "\n",
    "                read_length = num_values_per_datapoint * int(num_voxels) * 512\n",
    "                \n",
    "                # read voxels and reshape to (number of voxels, 8, 8, 8) because we read voxels in chunk\n",
    "                voxel_value = np.reshape(np.fromfile(db_file, dtype = 'f', count = read_length, offset = seek_distance), (int(num_voxels),8,8,8,num_values_per_datapoint))\n",
    "                \n",
    "                # build voxel pools\n",
    "                voxel_value_pool.extend(voxel_value)\n",
    "    \n",
    "    \n",
    "\n",
    "###################################################################################\n",
    "# step three: Building bucket for each point and calculate interpolation\n",
    "###################################################################################    \n",
    "t4 = time.perf_counter() \n",
    "# Calculate interpolation for each point\n",
    "ui_Lag = []\n",
    "ui_Spline = []\n",
    "# Loop over all queried points\n",
    "for j in range(len(points)):\n",
    "    voxel_point_value = []\n",
    "    Bucket = []\n",
    "    center_point = []\n",
    "    # num_voxel[j] is always 8, because we need 8 voxels\n",
    "    for i in range(num_voxel[j]):\n",
    "        # pull out correspoding 8 voxels from the voxels pool\n",
    "        index = np.where(points_cornercodes_all[j][i]==points_cornercodes_pool)[0][0]\n",
    "        voxel_point_value.append(voxel_value_pool[index]) \n",
    "    # build bucket for each queried point    \n",
    "    Bucket = formBucket(voxel_point_value,num_values_per_datapoint,Bucket_length = 16)\n",
    "    # need the center coordinate of the bucket (e.g, (7.5, 7.5, 7.5) for the first bucket) to calculate interpolation.\n",
    "    center_point = findCenter(B[j], dx)\n",
    "    ui_Lag.append(HessianFd4Lag4L(center_point,Bucket,dx,LW_Lag,NB))\n",
    "\n",
    "t5 = time.perf_counter()\n",
    "# TIC = (t2-t1)\n",
    "print('Find all 8 corners coordinates',(t2-t1),' sec')\n",
    "print('Find unique cornercode',(t3-t2),' sec')\n",
    "print('Load voxel pool',(t4-t3),' sec')\n",
    "print('Load voxel pool_creat_empty_dictionary',(t3_1-t3),' sec')\n",
    "print('Load voxel pool_creat_voxel_dictionary',(t3_2-t3_1),' sec')\n",
    "print('Load voxel pool_read_from dictionary',(t4-t3_2),' sec')\n",
    "print('Interpolation, Build Bucket + Calc',(t5-t4),' sec')\n",
    "print('In total',(t5-t1),' sec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8 (py38)",
   "language": "python",
   "name": "py38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
